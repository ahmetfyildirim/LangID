{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IMPORTS #####\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import math\n",
    "\n",
    "import operator\n",
    "\n",
    "import itertools\n",
    "\n",
    "##### IMPORTS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df_train = pd.read_csv(\"Notebook_Results/TRAIN-ENG-GER-FRE-N3-bin-informative.csv\", index_col='Unnamed: 0')\n",
    "df_train = df_train.dropna()\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "# print(\"df_train\")\n",
    "# print(df_train); print(df_train.dtypes)\n",
    "df_test = pd.read_csv(\"Notebook_Results/TEST-ENG-GER-FRE-N3-bin-informative.csv\", index_col='Unnamed: 0')\n",
    "df_test = df_test.dropna()\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "# print(\"df_test\")\n",
    "# print(df_test); print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word_NTE_gram_bin', 'word_C_gram_bin', 'word_K_gram_bin', 'word_ER_gram_bin', 'word_É_gram_bin', 'word_G_gram_bin', 'word_E_gram_bin', 'word_TE_gram_bin', 'word_Ä_gram_bin', 'word_TER_gram_bin', 'word_N_gram_bin', 'word_S_gram_bin', 'word_ERN_gram_bin', 'word_H_gram_bin', 'word_EI_gram_bin', 'word_NT_gram_bin', 'word_TEN_gram_bin', 'word_EN_gram_bin', 'word_Y_gram_bin', 'word_STE_gram_bin']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(set(df_train)-{'word', 'word_length', 'label'})\n",
    "print(feature_list)\n",
    "print(len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.3742382412437501, 1: 0.47129330415643567, 3: 0.15446845459981426}\n"
     ]
    }
   ],
   "source": [
    "label_grouped = df_train.groupby('label').count()\n",
    "label_values = df_train['label'].unique()\n",
    "label_sum = sum(label_grouped['word'])\n",
    "label_probs = dict.fromkeys(label_values, 0)\n",
    "for label_val in label_values:\n",
    "    label_probs[label_val] = label_grouped['word'][label_val]/label_sum\n",
    "print(label_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           word\n",
      "word_NTE_gram_bin label        \n",
      "0                 1      291747\n",
      "                  2      227191\n",
      "                  3       94331\n",
      "1                 1        4606\n",
      "                  2        8133\n",
      "                  3        2800\n",
      "                         word\n",
      "word_C_gram_bin label        \n",
      "0               1      193301\n",
      "                2      153492\n",
      "                3       68411\n",
      "1               1      103052\n",
      "                2       81832\n",
      "                3       28720\n",
      "                         word\n",
      "word_K_gram_bin label        \n",
      "0               1      276007\n",
      "                2      165549\n",
      "                3       96376\n",
      "1               1       20346\n",
      "                2       69775\n",
      "                3         755\n",
      "                          word\n",
      "word_ER_gram_bin label        \n",
      "0                1      245313\n",
      "                 2      137421\n",
      "                 3       81232\n",
      "1                1       51040\n",
      "                 2       97903\n",
      "                 3       15899\n",
      "                         word\n",
      "word_É_gram_bin label        \n",
      "0               1      296353\n",
      "                2      235264\n",
      "                3       68491\n",
      "1               1           0\n",
      "                2          60\n",
      "                3       28640\n",
      "                         word\n",
      "word_G_gram_bin label        \n",
      "0               1      236207\n",
      "                2      133144\n",
      "                3       82863\n",
      "1               1       60146\n",
      "                2      102180\n",
      "                3       14268\n",
      "                         word\n",
      "word_E_gram_bin label        \n",
      "0               1       93852\n",
      "                2       13315\n",
      "                3       25905\n",
      "1               1      202501\n",
      "                2      222009\n",
      "                3       71226\n",
      "                          word\n",
      "word_TE_gram_bin label        \n",
      "0                1      261943\n",
      "                 2      165806\n",
      "                 3       86824\n",
      "1                1       34410\n",
      "                 2       69518\n",
      "                 3       10307\n",
      "                         word\n",
      "word_Ä_gram_bin label        \n",
      "0               1      296353\n",
      "                2      211303\n",
      "                3       97131\n",
      "1               1           0\n",
      "                2       24021\n",
      "                3           0\n",
      "                           word\n",
      "word_TER_gram_bin label        \n",
      "0                 1      285268\n",
      "                  2      217678\n",
      "                  3       94491\n",
      "1                 1       11085\n",
      "                  2       17646\n",
      "                  3        2640\n",
      "                         word\n",
      "word_N_gram_bin label        \n",
      "0               1      145338\n",
      "                2       55956\n",
      "                3       48010\n",
      "1               1      151015\n",
      "                2      179368\n",
      "                3       49121\n",
      "                         word\n",
      "word_S_gram_bin label        \n",
      "0               1      148579\n",
      "                2       68294\n",
      "                3       46223\n",
      "1               1      147774\n",
      "                2      167030\n",
      "                3       50908\n",
      "                           word\n",
      "word_ERN_gram_bin label        \n",
      "0                 1      295002\n",
      "                  2      224851\n",
      "                  3       96734\n",
      "1                 1        1351\n",
      "                  2       10473\n",
      "                  3         397\n",
      "                         word\n",
      "word_H_gram_bin label        \n",
      "0               1      229973\n",
      "                2      123327\n",
      "                3       86616\n",
      "1               1       66380\n",
      "                2      111997\n",
      "                3       10515\n",
      "                          word\n",
      "word_EI_gram_bin label        \n",
      "0                1      292879\n",
      "                 2      190241\n",
      "                 3       96182\n",
      "1                1        3474\n",
      "                 2       45083\n",
      "                 3         949\n",
      "                          word\n",
      "word_NT_gram_bin label        \n",
      "0                1      273449\n",
      "                 2      215830\n",
      "                 3       77172\n",
      "1                1       22904\n",
      "                 2       19494\n",
      "                 3       19959\n",
      "                           word\n",
      "word_TEN_gram_bin label        \n",
      "0                 1      293868\n",
      "                  2      215154\n",
      "                  3       96078\n",
      "1                 1        2485\n",
      "                  2       20170\n",
      "                  3        1053\n",
      "                          word\n",
      "word_EN_gram_bin label        \n",
      "0                1      267034\n",
      "                 2      128224\n",
      "                 3       79916\n",
      "1                1       29319\n",
      "                 2      107100\n",
      "                 3       17215\n",
      "                         word\n",
      "word_Y_gram_bin label        \n",
      "0               1      243041\n",
      "                2      229417\n",
      "                3       94098\n",
      "1               1       53312\n",
      "                2        5907\n",
      "                3        3033\n",
      "                           word\n",
      "word_STE_gram_bin label        \n",
      "0                 1      292229\n",
      "                  2      218378\n",
      "                  3       95960\n",
      "1                 1        4124\n",
      "                  2       16946\n",
      "                  3        1171\n",
      "[[[9.84457724e-01 9.65439139e-01 9.71172952e-01]\n",
      "  [1.55422756e-02 3.45608608e-02 2.88270480e-02]]\n",
      "\n",
      " [[6.52266048e-01 6.52258163e-01 7.04316850e-01]\n",
      "  [3.47733952e-01 3.47741837e-01 2.95683150e-01]]\n",
      "\n",
      " [[9.31345389e-01 7.03493906e-01 9.92226992e-01]\n",
      "  [6.86546112e-02 2.96506094e-01 7.77300759e-03]]\n",
      "\n",
      " [[8.27772960e-01 5.83965086e-01 8.36313844e-01]\n",
      "  [1.72227040e-01 4.16034914e-01 1.63686156e-01]]\n",
      "\n",
      " [[1.00000000e+00 9.99745032e-01 7.05140480e-01]\n",
      "  [0.00000000e+00 2.54967619e-04 2.94859520e-01]]\n",
      "\n",
      " [[7.97046090e-01 5.65790145e-01 8.53105600e-01]\n",
      "  [2.02953910e-01 4.34209855e-01 1.46894400e-01]]\n",
      "\n",
      " [[3.16689893e-01 5.65815641e-02 2.66701671e-01]\n",
      "  [6.83310107e-01 9.43418436e-01 7.33298329e-01]]\n",
      "\n",
      " [[8.83888471e-01 7.04586018e-01 8.93885577e-01]\n",
      "  [1.16111529e-01 2.95413982e-01 1.06114423e-01]]\n",
      "\n",
      " [[1.00000000e+00 8.97923714e-01 1.00000000e+00]\n",
      "  [0.00000000e+00 1.02076286e-01 0.00000000e+00]]\n",
      "\n",
      " [[9.62595283e-01 9.25014023e-01 9.72820212e-01]\n",
      "  [3.74047167e-02 7.49859768e-02 2.71797881e-02]]\n",
      "\n",
      " [[4.90421896e-01 2.37782802e-01 4.94280920e-01]\n",
      "  [5.09578104e-01 7.62217198e-01 5.05719080e-01]]\n",
      "\n",
      " [[5.01358178e-01 2.90212643e-01 4.75883086e-01]\n",
      "  [4.98641822e-01 7.09787357e-01 5.24116914e-01]]\n",
      "\n",
      " [[9.95441247e-01 9.55495402e-01 9.95912736e-01]\n",
      "  [4.55875257e-03 4.45045979e-02 4.08726359e-03]]\n",
      "\n",
      " [[7.76010366e-01 5.24073193e-01 8.91744139e-01]\n",
      "  [2.23989634e-01 4.75926807e-01 1.08255861e-01]]\n",
      "\n",
      " [[9.88277493e-01 8.08421580e-01 9.90229690e-01]\n",
      "  [1.17225066e-02 1.91578420e-01 9.77031020e-03]]\n",
      "\n",
      " [[9.22713791e-01 9.17161021e-01 7.94514625e-01]\n",
      "  [7.72862094e-02 8.28389794e-02 2.05485375e-01]]\n",
      "\n",
      " [[9.91614730e-01 9.14288385e-01 9.89158971e-01]\n",
      "  [8.38527027e-03 8.57116146e-02 1.08410291e-02]]\n",
      "\n",
      " [[9.01067308e-01 5.44882800e-01 8.22765132e-01]\n",
      "  [9.89326918e-02 4.55117200e-01 1.77234868e-01]]\n",
      "\n",
      " [[8.20106427e-01 9.74898438e-01 9.68774130e-01]\n",
      "  [1.79893573e-01 2.51015621e-02 3.12258702e-02]]\n",
      "\n",
      " [[9.86084163e-01 9.27988645e-01 9.87944117e-01]\n",
      "  [1.39158369e-02 7.20113546e-02 1.20558833e-02]]]\n"
     ]
    }
   ],
   "source": [
    "feature_probs = np.zeros((20, 2, 3))\n",
    "for i in range(len(feature_list)):\n",
    "    feat = feature_list[i]\n",
    "    df_zip = df_train[[feat, 'label', 'word']]\n",
    "    grouped = df_zip.groupby([feat, 'label']).count()\n",
    "    levels = []\n",
    "    for j in range(2):\n",
    "        levels.append(grouped.index.levels[j].values)\n",
    "    new_index = pd.MultiIndex.from_product(levels, names=grouped.index.names)\n",
    "    grouped = grouped.reindex(new_index, fill_value=0)\n",
    "    for k in range(2):\n",
    "        for l in range(1,4):\n",
    "            pxny = grouped['word'][k][l]/label_sum\n",
    "            pxIy = pxny/label_probs[l]\n",
    "            feature_probs[i][k][l-1] = pxIy\n",
    "    print(grouped)\n",
    "print(feature_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104758    1\n",
      "Name: label, dtype: int64\n",
      "{1: 0.0029092472457682315, 2: 0.0019500819019741416, 3: 0.0009495872719404489}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## Testing on sample rows ##\n",
    "samp_row = df_test.sample(1)\n",
    "# samp_lab_prob = np.ones((1,3), dtype=int)\n",
    "# samp_lab_prob = [label_probs[1], label_probs[2], label_probs[3]]\n",
    "samp_lab_prob = {1:label_probs[1], 2:label_probs[2], 3:label_probs[3]}\n",
    "# print(samp_lab_prob)\n",
    "# print(samp_lab_prob[2])\n",
    "# print(feature_probs)\n",
    "# print(feature_probs[19][1][2])\n",
    "for lab in range(1,4):\n",
    "    for i in range(len(feature_list)):\n",
    "        feat = feature_list[i]\n",
    "        temp1 = feature_probs[i]\n",
    "#         print(temp1)\n",
    "        temp2 = temp1[samp_row[feat]][0]\n",
    "#         print(temp2)\n",
    "        temp3 = temp2[lab-1]\n",
    "#         print(temp3)\n",
    "        pxIy = temp3\n",
    "#         samp_lab_prob[lab-1] = samp_lab_prob[lab-1] * pxIy\n",
    "        samp_lab_prob[lab] = samp_lab_prob[lab] * pxIy\n",
    "print(samp_row['label'])\n",
    "print(samp_lab_prob)\n",
    "print(max(samp_lab_prob, key=samp_lab_prob.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df_test['p_label'] = 0\n",
    "for ind in range(len(df_test.index)):\n",
    "    samp_lab_prob = {1:label_probs[1], 2:label_probs[2], 3:label_probs[3]}\n",
    "    row = df_test.loc[[ind]]\n",
    "    for lab in range(1,4):\n",
    "        for i in range(len(feature_list)):\n",
    "            feat = feature_list[i]\n",
    "            pxIy = feature_probs[i][row[feat]][0][lab-1]\n",
    "            samp_lab_prob[lab] = samp_lab_prob[lab] * pxIy\n",
    "#     row['p_label'] = max(samp_lab_prob, key=samp_lab_prob.get)\n",
    "    pred = max(samp_lab_prob, key=samp_lab_prob.get)\n",
    "    df_test.set_value(ind, 'p_label', pred)\n",
    "#     print(ind)\n",
    "#     print(df_test.loc[[ind]]['p_label'])\n",
    "#     print(df_test.loc[[ind]]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of wrong predictions 40015\n",
      "# of samples 156257\n",
      "Accuracy 0.2560845274131719\n",
      "English tp fn fp tn set-size\n",
      "62274\n",
      "11469\n",
      "25938\n",
      "56576\n",
      "73743\n",
      "German tp fn fp tn set-size\n",
      "45248\n",
      "13221\n",
      "12553\n",
      "85235\n",
      "58469\n",
      "French tp fn fp tn set-size\n",
      "8720\n",
      "15325\n",
      "1524\n",
      "130688\n",
      "24045\n",
      "English recall precision\n",
      "0.8444733737439486\n",
      "0.7059583730104748\n",
      "German recall precision\n",
      "0.7738801758196652\n",
      "0.7828238265773949\n",
      "French recall precision\n",
      "0.36265335828654605\n",
      "0.8512299882858259\n"
     ]
    }
   ],
   "source": [
    "mistak = 0\n",
    "total = len(df_test.index)\n",
    "tp1 = 0\n",
    "tp2 = 0\n",
    "tp3 = 0\n",
    "fn1 = 0\n",
    "fn2 = 0\n",
    "fn3 = 0\n",
    "fp1 = 0\n",
    "fp2 = 0\n",
    "fp3 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "total3 = 0\n",
    "for ind in range(len(df_test.index)):\n",
    "    row = df_test.loc[[ind]]\n",
    "    l = row['label'][ind]\n",
    "    p = row['p_label'][ind]\n",
    "    if l == 1:\n",
    "        total1 = total1 + 1\n",
    "        if p == 2:\n",
    "            fn1 = fn1 + 1\n",
    "            fp2 = fp2 + 1\n",
    "        elif p == 3:\n",
    "            fn1 = fn1 + 1\n",
    "            fp3 = fp3 + 1\n",
    "        elif p == 1:\n",
    "            tp1 = tp1 + 1\n",
    "    elif l == 2:\n",
    "        total2 = total2 + 1\n",
    "        if p == 1:\n",
    "            fn2 = fn2 + 1\n",
    "            fp1 = fp1 + 1\n",
    "        elif p == 3:\n",
    "            fn2 = fn2 + 1\n",
    "            fp3 = fp3 + 1\n",
    "        elif p == 2:\n",
    "            tp2 = tp2 + 1\n",
    "    else:\n",
    "        total3 = total3 + 1\n",
    "        if p == 1:\n",
    "            fn3 = fn3 + 1\n",
    "            fp1 = fp1 + 1\n",
    "        elif p == 2:\n",
    "            fn3 = fn3 + 1\n",
    "            fp2 = fp2 + 1\n",
    "        elif p == 3:\n",
    "            tp3 = tp3 + 1\n",
    "        \n",
    "    if l != p:\n",
    "        mistak = mistak + 1\n",
    "#     if ind % 25000 == 0:\n",
    "#         print(ind)\n",
    "print(\"# of wrong predictions %s\" % (mistak))\n",
    "print(\"# of samples %s\" % (total))\n",
    "print(\"Accuracy %s\" % (mistak/total))\n",
    "print('English tp fn fp tn set-size')\n",
    "print(tp1)\n",
    "print(fn1)\n",
    "print(fp1)\n",
    "print(total - tp1 - fn1 - fp1)\n",
    "print(total1)\n",
    "print('German tp fn fp tn set-size')\n",
    "print(tp2)\n",
    "print(fn2)\n",
    "print(fp2)\n",
    "print(total - tp2 - fn2 - fp2)\n",
    "print(total2)\n",
    "print('French tp fn fp tn set-size')\n",
    "print(tp3)\n",
    "print(fn3)\n",
    "print(fp3)\n",
    "print(total - tp3 - fn3 - fp3)\n",
    "print(total3)\n",
    "print('English recall precision')\n",
    "r1 = tp1 / (tp1 + fn1)\n",
    "p1 = tp1 / (tp1 + fp1)\n",
    "print(tp1 / (tp1 + fn1))\n",
    "print(tp1 / (tp1 + fp1))\n",
    "print('German recall precision')\n",
    "r2 = tp2 / (tp2 + fn2)\n",
    "p2 = tp2 / (tp2 + fp2)\n",
    "print(tp2 / (tp2 + fn2))\n",
    "print(tp2 / (tp2 + fp2))\n",
    "print('French recall precision')\n",
    "r3 = tp3 / (tp3 + fn3)\n",
    "p3 = tp3 / (tp3 + fp3)\n",
    "print(tp3 / (tp3 + fn3))\n",
    "print(tp3 / (tp3 + fp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7151986149469226\n"
     ]
    }
   ],
   "source": [
    "avgr = (r1 + r2 + r3) / 3\n",
    "avgp = (p1 + p2 + p3) / 3\n",
    "# print(avgr)\n",
    "# print(avgp)\n",
    "f1 = 2 * (avgp * avgr) / (avgp + avgr)\n",
    "print(\"F1 score: %s\" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayes p(y|x) ~ p(x1|y)...p(xp|y)p(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
